{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prTjEIdOWzTx",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3TvAVM8XT2kk",
    "outputId": "eb0a4462-0596-4cbc-b775-6d4157c0bf10",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "\n",
    "MOUNT_POINT = '/content/gdrive'\n",
    "DATA_DIR = os.path.join(MOUNT_POINT, 'My Drive', 'Colab Notebooks', 'Checkpoints')\n",
    "drive.mount(MOUNT_POINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XQ9SdIw-cv9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Input, Add, Flatten, Activation\n",
    "from keras.layers import Dense, BatchNormalization\n",
    "from keras.layers import Conv2D, AveragePooling2D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCQJOhqZNtJ8",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUW4EBVcNwsd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "\n",
    "TRAIN_DATA_PERCENT = 90\n",
    "DEPTH = 56\n",
    "HEIGHT, WIDTH, CHANNELS = 48, 48, 1\n",
    "CLASSES = 7\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LR_INIT = 0.0004\n",
    "AUGMENTATION = True\n",
    "MODEL_TYPE = \"FER_ResNet{}_RoI\".format(DEPTH)\n",
    "\n",
    "LOAD = False\n",
    "LAST_EPOCH = 0\n",
    "\n",
    "LOAD_PATH = os.path.join(DATA_DIR, \"FER_ResNet56_RoI_002-2.22.hdf5\")\n",
    "CSV_PATH = os.path.join(DATA_DIR, \"FER_ResNet56_RoI.csv\")\n",
    "SAVE_PATH = os.path.join(DATA_DIR, \"FER_ResNet56_RoI_{epoch:03d}-{val_loss:.2f}.hdf5\")\n",
    "\n",
    "OPTIMIZER = Adam(learning_rate=LR_INIT)\n",
    "LR_REDUCER = ReduceLROnPlateau(\n",
    "  monitor='val_loss',\n",
    "  factor=0.5,\n",
    "  patience=6,\n",
    "  min_delta=0.0001,\n",
    "  verbose=1\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "  filepath=SAVE_PATH,\n",
    "  monitor='val_loss',\n",
    "  save_best_only=False,\n",
    "  save_weights_only=False,\n",
    "  mode='auto',\n",
    "  verbose=1\n",
    ")\n",
    "csv_logger = CSVLogger(CSV_PATH, append=True)\n",
    "callbacks = [checkpoint, csv_logger, LR_REDUCER]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tkOmNs_OcZg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FqwZMjlSYAQS",
    "outputId": "7eb287d2-e131-415c-c879-4cb6b6f013f4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1t1GH1o5t9WgTE1ODB4QfpzhmuKImFY1w\n",
      "To: /content/fer-2013-images.npy\n",
      "100% 82.7M/82.7M [00:00<00:00, 226MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1LldCqbvgwQSt2uBrU9L33Oq5SmnQxq_Z\n",
      "To: /content/fer-2013-labels.npy\n",
      "100% 1.00M/1.00M [00:00<00:00, 137MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown 1t1GH1o5t9WgTE1ODB4QfpzhmuKImFY1w\n",
    "!gdown 1LldCqbvgwQSt2uBrU9L33Oq5SmnQxq_Z\n",
    "!gdown 1eUKhOrl_jD44oLzywE2Q6ei9uWWvc1aW\n",
    "\n",
    "dataset_images = np.load('fer-2013-images.npy')\n",
    "dataset_labels = np.load('fer-2013-labels.npy')\n",
    "dataset_landmarks = np.load('fer-2013-dlib-landmarks.npz')['landmarks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYvxIGY59DeV",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create train and test data and labels\n",
    "train_data_count = math.floor(len(dataset_images) * TRAIN_DATA_PERCENT / 100)\n",
    "test_data_count = len(dataset_images) - train_data_count\n",
    "\n",
    "# Shuffle all data in dataset. \n",
    "indexes = np.arange(len(dataset_images))\n",
    "np.random.shuffle(indexes)\n",
    "dataset_images = dataset_images[indexes]\n",
    "dataset_labels = dataset_labels[indexes]\n",
    "dataset_landmarks = dataset_landmarks[indexes]\n",
    "\n",
    "# Split train and test data\n",
    "X_train = dataset_images[:train_data_count].astype('float32')\n",
    "X_train_landmarks = dataset_landmarks[:train_data_count].astype('float32')\n",
    "Y_train = dataset_labels[:train_data_count]\n",
    "X_test = dataset_images[train_data_count:].astype('float32')\n",
    "X_test_landmarks = dataset_landmarks[train_data_count:].astype('float32')\n",
    "Y_test = dataset_labels[train_data_count:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_landmarks.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_test_landmarks.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Glj3LuQh9Gok",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = 3\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(X_train[index].squeeze(axis=2))\n",
    "ax2.imshow(X_train_landmarks[index].squeeze(axis=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DcoLaBHZAbX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def generate_generator_multiple(\n",
    "  gen_args,\n",
    "  in1,\n",
    "  in2,\n",
    "  labels,\n",
    "  batch_size,\n",
    "  seed,\n",
    "):\n",
    "  generator = ImageDataGenerator(**gen_args)\n",
    "  genX1 = generator.flow(\n",
    "    x=in1,\n",
    "    y=labels,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "  )\n",
    "  genX2 = generator.flow(\n",
    "    x=in2,\n",
    "    y=labels,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed,\n",
    "  )\n",
    "  while True:\n",
    "    X1i = genX1.next()\n",
    "    X2i = genX2.next()\n",
    "    yield [X1i[0], X2i[0]], X2i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q7Pv-AOlALVv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Train Data ##\n",
    "if not AUGMENTATION:\n",
    "  train_args = dict(rescale=1./255)\n",
    "\n",
    "else:\n",
    "  train_args = dict(\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=1./255,\n",
    "    # set range for random zoom\n",
    "    zoom_range=0.3,\n",
    "    # randomly flip images\n",
    "    horizontal_flip=True,\n",
    "    # randomly flip images\n",
    "    vertical_flip=False,\n",
    "    # set input mean to 0 over the dataset\n",
    "    featurewise_center=False,\n",
    "    # set each sample mean to 0\n",
    "    samplewise_center=False,\n",
    "    # divide inputs by std of dataset\n",
    "    featurewise_std_normalization=False,\n",
    "    # divide each input by its std\n",
    "    samplewise_std_normalization=False,\n",
    "    # apply ZCA whitening\n",
    "    zca_whitening=False,\n",
    "    # epsilon for ZCA whitening\n",
    "    zca_epsilon=1e-06,\n",
    "    # randomly rotate images in the range (deg 0 to 180)\n",
    "    rotation_range=0,\n",
    "    # randomly shift images horizontally\n",
    "    width_shift_range=0.1,\n",
    "    # randomly shift images vertically\n",
    "    height_shift_range=0.1,\n",
    "    # set range for random shear\n",
    "    shear_range=0.,\n",
    "    # set range for random channel shifts\n",
    "    channel_shift_range=0.,\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    # value used for fill_mode = \"constant\"\n",
    "    cval=0.,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format=None,\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0\n",
    "  )\n",
    "\n",
    "train_set = generate_generator_multiple(\n",
    "  gen_args=train_args,\n",
    "  in1=X_train,\n",
    "  in2=X_train_landmarks,\n",
    "  labels=Y_train,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed=SEED,\n",
    ") \n",
    "\n",
    "## Test Data ##\n",
    "test_args = dict(rescale=1./255)\n",
    "test_set = generate_generator_multiple(\n",
    "  gen_args=test_args,\n",
    "  in1=X_test,\n",
    "  in2=X_test_landmarks,\n",
    "  labels=Y_test,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jK8s2HQhNMXy",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2SAL4DD_hQ2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def resnet_layer(\n",
    "  inputs,\n",
    "  num_filters=16,\n",
    "  kernel_size=3,\n",
    "  strides=1,\n",
    "  activation='relu',\n",
    "  batch_normalization=True,\n",
    "  conv_first=True\n",
    "):\n",
    "  \"\"\"\n",
    "  2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "  # Arguments\n",
    "    inputs (tensor): input tensor from input image or previous layer\n",
    "    num_filters (int): Conv2D number of filters\n",
    "    kernel_size (int): Conv2D square kernel dimensions\n",
    "    strides (int): Conv2D square stride dimensions\n",
    "    activation (string): activation name\n",
    "    batch_normalization (bool): whether to include batch normalization\n",
    "    conv_first (bool): conv-bn-activation (T) or bn-activation-conv (F)\n",
    "    \n",
    "  # Returns\n",
    "    x (tensor): tensor as input to the next layer\n",
    "  \"\"\"\n",
    "\n",
    "  conv = Conv2D(\n",
    "    num_filters,\n",
    "    kernel_size,\n",
    "    strides,\n",
    "    padding='same',\n",
    "    kernel_initializer='he_normal',\n",
    "    kernel_regularizer=l2(1e-4)\n",
    "  )\n",
    "\n",
    "  x = inputs\n",
    "\n",
    "  if conv_first:\n",
    "    x = conv(x)\n",
    "    if batch_normalization:\n",
    "      x = BatchNormalization()(x)\n",
    "    if activation is not None:\n",
    "      x = Activation(activation)(x)\n",
    "  else:\n",
    "    if batch_normalization:\n",
    "      x = BatchNormalization()(x)\n",
    "    if activation is not None:\n",
    "      x = Activation(activation)(x)\n",
    "    x = conv(x)\n",
    "\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwtMGkKu-yKw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ResNet V2 (with bottleneck blocks) model for small datasets.\n",
    "def my_model(input1, input2, depth, num_classes):\n",
    "  \"\"\"\n",
    "  ResNet Version 2 Model builder\n",
    "  Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D\n",
    "  or also known as bottleneck layer\n",
    "  First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "  Second and onwards shortcut connection is identity.\n",
    "  At the beginning of each stage, the feature map size is halved (down-sampled)\n",
    "  by a convolutional layer with strides=2, while the number of filter maps is\n",
    "  doubled. Within each stage, the layers have the same number filters and the\n",
    "  same filter map sizes.\n",
    "  Feature maps sizes:\n",
    "  conv1  : 32x32,  16\n",
    "  stage 0: 32x32,  64\n",
    "  stage 1: 16x16, 128\n",
    "  stage 2:  8x8,  256\n",
    "\n",
    "  # Arguments\n",
    "    input_shape (tensor): shape of input image tensor\n",
    "    depth (int): number of core convolutional layers\n",
    "    num_classes (int): number of classes\n",
    "\n",
    "  # Returns\n",
    "    model (Model): Keras model instance\n",
    "  \"\"\"\n",
    "\n",
    "  if (depth - 2) % 9 != 0:\n",
    "    raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "\n",
    "  # Start model definition.\n",
    "  num_filters_in = 16\n",
    "  num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "  X_input1 = Input(input1)\n",
    "  X_input2 = Input(input2)\n",
    "\n",
    "  x1 = resnet_layer(\n",
    "    inputs=X_input1,\n",
    "    num_filters=num_filters_in,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=None,\n",
    "    batch_normalization=None,\n",
    "    conv_first=True\n",
    "  )\n",
    "\n",
    "  x2 = resnet_layer(\n",
    "    inputs=X_input2,\n",
    "    num_filters=num_filters_in,\n",
    "    kernel_size=3,\n",
    "    strides=1,\n",
    "    activation=None,\n",
    "    batch_normalization=None,\n",
    "    conv_first=True\n",
    "  )\n",
    "\n",
    "  x = Add()([x1, x2])\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  num_filters_out = 0\n",
    "\n",
    "  # Instantiate the stack of residual units\n",
    "  for stage in range(3):\n",
    "    for res_block in range(num_res_blocks):\n",
    "      activation = 'relu'\n",
    "      batch_normalization = True\n",
    "      strides = 1\n",
    "      if stage == 0:\n",
    "        num_filters_out = num_filters_in * 4\n",
    "        if res_block == 0:  # first layer and first stage\n",
    "          activation = None\n",
    "          batch_normalization = False\n",
    "      else:\n",
    "        num_filters_out = num_filters_in * 2\n",
    "        if res_block == 0:  # first layer but not first stage\n",
    "          strides = 2    # down-sample\n",
    "\n",
    "      # bottleneck residual unit\n",
    "      y = resnet_layer(\n",
    "        inputs=x,\n",
    "        num_filters=num_filters_in,\n",
    "        kernel_size=1,\n",
    "        strides=strides,\n",
    "        activation=activation,\n",
    "        batch_normalization=batch_normalization,\n",
    "        conv_first=False\n",
    "      )\n",
    "\n",
    "      y = resnet_layer(\n",
    "        inputs=y,\n",
    "        num_filters=num_filters_in,\n",
    "        conv_first=False\n",
    "      )\n",
    "\n",
    "      y = resnet_layer(\n",
    "        inputs=y,\n",
    "        num_filters=num_filters_out,\n",
    "        kernel_size=1,\n",
    "        conv_first=False\n",
    "      )\n",
    "\n",
    "      if res_block == 0:\n",
    "        # linear projection residual shortcut connection to match\n",
    "        # changed dims\n",
    "        x = resnet_layer(\n",
    "          inputs=x,\n",
    "          num_filters=num_filters_out,\n",
    "          kernel_size=1,\n",
    "          strides=strides,\n",
    "          activation=None,\n",
    "          batch_normalization=False\n",
    "        )\n",
    "\n",
    "      x = Add()([x, y])\n",
    "\n",
    "    num_filters_in = num_filters_out\n",
    "\n",
    "  # Add classifier on top.\n",
    "  # v2 has BN-ReLU before Pooling\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu')(x)\n",
    "  x = AveragePooling2D(pool_size=8)(x)\n",
    "  y = Flatten()(x)\n",
    "  \n",
    "  outputs = Dense(\n",
    "    num_classes,\n",
    "    activation='softmax',\n",
    "    kernel_initializer='he_normal'\n",
    "  )(y)\n",
    "\n",
    "  # Instantiate model.\n",
    "  model = Model(inputs=[X_input1, X_input2], outputs=outputs, name=MODEL_TYPE)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2J3UOifINRAz",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8gCb7PSVAH-n",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if LOAD:\n",
    "  model = load_model(LOAD_PATH)\n",
    "else:\n",
    "  model = my_model(\n",
    "    input1=(HEIGHT, WIDTH, CHANNELS),\n",
    "    input2=(HEIGHT, WIDTH, CHANNELS),\n",
    "    depth=DEPTH,\n",
    "    num_classes=CLASSES\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=OPTIMIZER,\n",
    "    metrics=['accuracy']\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "9mSpM8HHVau2",
    "outputId": "59fe60cb-d128-4b7c-aa79-26023c192758",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FER_ResNet56_RoI\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 48, 48, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 48, 48, 16)   160         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 48, 48, 16)   160         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 48, 48, 16)   0           ['conv2d[0][0]',                 \n",
      "                                                                  'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 48, 48, 16)  64          ['add[0][0]']                    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 48, 48, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 48, 48, 16)   272         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 48, 48, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 48, 48, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 48, 48, 16)   2320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 48, 48, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 48, 48, 16)   0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 48, 48, 64)   1088        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 48, 48, 64)   1088        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 48, 48, 64)   0           ['conv2d_5[0][0]',               \n",
      "                                                                  'conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 48, 48, 64)  256         ['add_1[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 48, 48, 64)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 48, 48, 16)   1040        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 48, 48, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 48, 48, 16)   0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 48, 48, 16)   2320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 48, 48, 16)  64          ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 48, 48, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 48, 48, 64)   1088        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 48, 48, 64)   0           ['add_1[0][0]',                  \n",
      "                                                                  'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 48, 48, 64)  256         ['add_2[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 48, 48, 64)   0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 48, 48, 16)   1040        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 48, 48, 16)  64          ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 48, 48, 16)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 48, 48, 16)   2320        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 48, 48, 16)  64          ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 48, 48, 16)   0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 48, 48, 64)   1088        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 48, 48, 64)   0           ['add_2[0][0]',                  \n",
      "                                                                  'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 48, 48, 64)  256         ['add_3[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 48, 48, 64)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 48, 48, 16)   1040        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 48, 48, 16)  64          ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 48, 48, 16)   0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 48, 48, 16)   2320        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 48, 48, 16)  64          ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 48, 48, 16)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 48, 48, 64)   1088        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 48, 48, 64)   0           ['add_3[0][0]',                  \n",
      "                                                                  'conv2d_14[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 48, 48, 64)  256         ['add_4[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 48, 48, 64)   0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 48, 48, 16)   1040        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 48, 48, 16)  64          ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 48, 48, 16)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 48, 48, 16)   2320        ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 48, 48, 16)  64          ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 48, 48, 16)   0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 48, 48, 64)   1088        ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 48, 48, 64)   0           ['add_4[0][0]',                  \n",
      "                                                                  'conv2d_17[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 48, 48, 64)  256         ['add_5[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 48, 48, 64)   0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 48, 48, 16)   1040        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 48, 48, 16)  64          ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 48, 48, 16)   0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 48, 48, 16)   2320        ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 48, 48, 16)  64          ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 48, 48, 16)   0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 48, 48, 64)   1088        ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 48, 48, 64)   0           ['add_5[0][0]',                  \n",
      "                                                                  'conv2d_20[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 48, 48, 64)  256         ['add_6[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 48, 48, 64)   0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)             (None, 24, 24, 64)   4160        ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 24, 24, 64)  256         ['conv2d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)             (None, 24, 24, 64)   36928       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 24, 24, 64)  256         ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)             (None, 24, 24, 128)  8320        ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)             (None, 24, 24, 128)  8320        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 24, 24, 128)  0           ['conv2d_24[0][0]',              \n",
      "                                                                  'conv2d_23[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 24, 24, 128)  512        ['add_7[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 24, 24, 128)  0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)             (None, 24, 24, 64)   8256        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 24, 24, 64)  256         ['conv2d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 24, 24, 64)   36928       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 24, 24, 64)  256         ['conv2d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_23[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 24, 24, 128)  8320        ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 24, 24, 128)  0           ['add_7[0][0]',                  \n",
      "                                                                  'conv2d_27[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 24, 24, 128)  512        ['add_8[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 24, 24, 128)  0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 24, 24, 64)   8256        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 24, 24, 64)  256         ['conv2d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 24, 24, 64)   36928       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 24, 24, 64)  256         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 24, 24, 128)  8320        ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 24, 24, 128)  0           ['add_8[0][0]',                  \n",
      "                                                                  'conv2d_30[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 24, 24, 128)  512        ['add_9[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 24, 24, 128)  0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 24, 24, 64)   8256        ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 24, 24, 64)  256         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 24, 24, 64)   36928       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 24, 24, 64)  256         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 24, 24, 128)  8320        ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 24, 24, 128)  0           ['add_9[0][0]',                  \n",
      "                                                                  'conv2d_33[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 24, 24, 128)  512        ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 24, 24, 128)  0           ['batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 24, 24, 64)   8256        ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 24, 24, 64)  256         ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 24, 24, 64)   36928       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 24, 24, 64)  256         ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 24, 24, 128)  8320        ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 24, 24, 128)  0           ['add_10[0][0]',                 \n",
      "                                                                  'conv2d_36[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 24, 24, 128)  512        ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 24, 24, 128)  0           ['batch_normalization_33[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 24, 24, 64)   8256        ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 24, 24, 64)  256         ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 24, 24, 64)   36928       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 24, 24, 64)  256         ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 24, 24, 64)   0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 24, 24, 128)  8320        ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 24, 24, 128)  0           ['add_11[0][0]',                 \n",
      "                                                                  'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 24, 24, 128)  512        ['add_12[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 24, 24, 128)  0           ['batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 12, 12, 128)  16512       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 12, 12, 128)  512        ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 12, 12, 128)  147584      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 12, 12, 128)  512        ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 12, 12, 256)  33024       ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 12, 12, 256)  33024       ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 12, 12, 256)  0           ['conv2d_43[0][0]',              \n",
      "                                                                  'conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 12, 12, 256)  1024       ['add_13[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 12, 12, 256)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 12, 12, 128)  32896       ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 12, 12, 128)  512        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 12, 12, 128)  147584      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 12, 12, 128)  512        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 12, 12, 256)  33024       ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 12, 12, 256)  0           ['add_13[0][0]',                 \n",
      "                                                                  'conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 12, 12, 256)  1024       ['add_14[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 12, 12, 256)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 12, 12, 128)  32896       ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 12, 12, 128)  512        ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 12, 12, 128)  147584      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 12, 12, 128)  512        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 12, 12, 256)  33024       ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 12, 12, 256)  0           ['add_14[0][0]',                 \n",
      "                                                                  'conv2d_49[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 12, 12, 256)  1024       ['add_15[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 12, 12, 256)  0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 12, 12, 128)  32896       ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 12, 12, 128)  512        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 12, 12, 128)  147584      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 12, 12, 128)  512        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 12, 12, 256)  33024       ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 12, 12, 256)  0           ['add_15[0][0]',                 \n",
      "                                                                  'conv2d_52[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 12, 12, 256)  1024       ['add_16[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 12, 12, 256)  0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 12, 12, 128)  32896       ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 12, 12, 128)  512        ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 12, 12, 128)  147584      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 12, 12, 128)  512        ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 12, 12, 256)  33024       ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 12, 12, 256)  0           ['add_16[0][0]',                 \n",
      "                                                                  'conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 12, 12, 256)  1024       ['add_17[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 12, 12, 256)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 12, 12, 128)  32896       ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 12, 12, 128)  512        ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 12, 12, 128)  147584      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 12, 12, 128)  512        ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 12, 12, 128)  0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 12, 12, 256)  33024       ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 12, 12, 256)  0           ['add_17[0][0]',                 \n",
      "                                                                  'conv2d_58[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 12, 12, 256)  1024       ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 12, 12, 256)  0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 256)   0           ['activation_54[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 256)          0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 7)            1799        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,672,839\n",
      "Trainable params: 1,662,439\n",
      "Non-trainable params: 10,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "bottnT3gVbbb",
    "outputId": "924fbabc-4d89-4b0f-b6fb-502de0868269",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(\n",
    "  model,\n",
    "  to_file=\"./{}_structure.png\".format(MODEL_TYPE),\n",
    "  show_shapes=True,\n",
    "  show_layer_names=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQLZiyQsV9CX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "euhae7A6BXCk",
    "outputId": "b16434b1-ea30-44fd-c006-c67da80cfc07",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 2.5998 - accuracy: 0.3484\n",
      "Epoch 1: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_001-2.36.hdf5\n",
      "505/505 [==============================] - 98s 160ms/step - loss: 2.5998 - accuracy: 0.3484 - val_loss: 2.3612 - val_accuracy: 0.3865 - lr: 4.0000e-04\n",
      "Epoch 2/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 2.2346 - accuracy: 0.4067\n",
      "Epoch 2: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_002-2.21.hdf5\n",
      "505/505 [==============================] - 80s 158ms/step - loss: 2.2346 - accuracy: 0.4067 - val_loss: 2.2144 - val_accuracy: 0.3879 - lr: 4.0000e-04\n",
      "Epoch 3/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 2.0433 - accuracy: 0.4297\n",
      "Epoch 3: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_003-2.04.hdf5\n",
      "505/505 [==============================] - 80s 158ms/step - loss: 2.0433 - accuracy: 0.4297 - val_loss: 2.0423 - val_accuracy: 0.4043 - lr: 4.0000e-04\n",
      "Epoch 4/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.9142 - accuracy: 0.4488\n",
      "Epoch 4: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_004-2.16.hdf5\n",
      "505/505 [==============================] - 79s 156ms/step - loss: 1.9142 - accuracy: 0.4488 - val_loss: 2.1589 - val_accuracy: 0.4113 - lr: 4.0000e-04\n",
      "Epoch 5/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.8157 - accuracy: 0.4732\n",
      "Epoch 5: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_005-1.81.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.8157 - accuracy: 0.4732 - val_loss: 1.8085 - val_accuracy: 0.4820 - lr: 4.0000e-04\n",
      "Epoch 6/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.7376 - accuracy: 0.4923\n",
      "Epoch 6: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_006-1.76.hdf5\n",
      "505/505 [==============================] - 79s 156ms/step - loss: 1.7376 - accuracy: 0.4923 - val_loss: 1.7638 - val_accuracy: 0.4767 - lr: 4.0000e-04\n",
      "Epoch 7/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.6697 - accuracy: 0.5139\n",
      "Epoch 7: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_007-1.91.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.6697 - accuracy: 0.5139 - val_loss: 1.9093 - val_accuracy: 0.4436 - lr: 4.0000e-04\n",
      "Epoch 8/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.6133 - accuracy: 0.5271\n",
      "Epoch 8: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_008-1.58.hdf5\n",
      "505/505 [==============================] - 79s 156ms/step - loss: 1.6133 - accuracy: 0.5271 - val_loss: 1.5787 - val_accuracy: 0.5378 - lr: 4.0000e-04\n",
      "Epoch 9/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.5695 - accuracy: 0.5355\n",
      "Epoch 9: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_009-1.53.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.5695 - accuracy: 0.5355 - val_loss: 1.5316 - val_accuracy: 0.5556 - lr: 4.0000e-04\n",
      "Epoch 10/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.5323 - accuracy: 0.5492\n",
      "Epoch 10: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_010-1.58.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.5323 - accuracy: 0.5492 - val_loss: 1.5813 - val_accuracy: 0.5394 - lr: 4.0000e-04\n",
      "Epoch 11/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.4978 - accuracy: 0.5592\n",
      "Epoch 11: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_011-1.55.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.4978 - accuracy: 0.5592 - val_loss: 1.5527 - val_accuracy: 0.5288 - lr: 4.0000e-04\n",
      "Epoch 12/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.4654 - accuracy: 0.5659\n",
      "Epoch 12: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_012-1.48.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.4654 - accuracy: 0.5659 - val_loss: 1.4766 - val_accuracy: 0.5570 - lr: 4.0000e-04\n",
      "Epoch 13/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.4415 - accuracy: 0.5726\n",
      "Epoch 13: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_013-1.60.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.4415 - accuracy: 0.5726 - val_loss: 1.6023 - val_accuracy: 0.5391 - lr: 4.0000e-04\n",
      "Epoch 14/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.4172 - accuracy: 0.5799\n",
      "Epoch 14: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_014-1.45.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.4172 - accuracy: 0.5799 - val_loss: 1.4490 - val_accuracy: 0.5637 - lr: 4.0000e-04\n",
      "Epoch 15/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.3995 - accuracy: 0.5825\n",
      "Epoch 15: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_015-1.45.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.3995 - accuracy: 0.5825 - val_loss: 1.4525 - val_accuracy: 0.5779 - lr: 4.0000e-04\n",
      "Epoch 16/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.3802 - accuracy: 0.5906\n",
      "Epoch 16: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_016-1.54.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.3802 - accuracy: 0.5906 - val_loss: 1.5402 - val_accuracy: 0.5288 - lr: 4.0000e-04\n",
      "Epoch 17/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.3592 - accuracy: 0.5986\n",
      "Epoch 17: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_017-1.42.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.3592 - accuracy: 0.5986 - val_loss: 1.4189 - val_accuracy: 0.5776 - lr: 4.0000e-04\n",
      "Epoch 18/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.3451 - accuracy: 0.6023\n",
      "Epoch 18: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_018-1.41.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.3451 - accuracy: 0.6023 - val_loss: 1.4118 - val_accuracy: 0.5801 - lr: 4.0000e-04\n",
      "Epoch 19/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.3327 - accuracy: 0.6027\n",
      "Epoch 19: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_019-1.44.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.3327 - accuracy: 0.6027 - val_loss: 1.4398 - val_accuracy: 0.5595 - lr: 4.0000e-04\n",
      "Epoch 20/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.3181 - accuracy: 0.6043\n",
      "Epoch 20: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_020-1.51.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.3181 - accuracy: 0.6043 - val_loss: 1.5104 - val_accuracy: 0.5514 - lr: 4.0000e-04\n",
      "Epoch 21/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.3041 - accuracy: 0.6119\n",
      "Epoch 21: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_021-1.41.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.3041 - accuracy: 0.6119 - val_loss: 1.4133 - val_accuracy: 0.5731 - lr: 4.0000e-04\n",
      "Epoch 22/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2947 - accuracy: 0.6134\n",
      "Epoch 22: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_022-1.56.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2947 - accuracy: 0.6134 - val_loss: 1.5554 - val_accuracy: 0.5311 - lr: 4.0000e-04\n",
      "Epoch 23/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2821 - accuracy: 0.6177\n",
      "Epoch 23: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_023-1.31.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2821 - accuracy: 0.6177 - val_loss: 1.3083 - val_accuracy: 0.6021 - lr: 4.0000e-04\n",
      "Epoch 24/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2657 - accuracy: 0.6192\n",
      "Epoch 24: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_024-1.48.hdf5\n",
      "505/505 [==============================] - 80s 158ms/step - loss: 1.2657 - accuracy: 0.6192 - val_loss: 1.4816 - val_accuracy: 0.5639 - lr: 4.0000e-04\n",
      "Epoch 25/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2610 - accuracy: 0.6216\n",
      "Epoch 25: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_025-1.36.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2610 - accuracy: 0.6216 - val_loss: 1.3619 - val_accuracy: 0.5913 - lr: 4.0000e-04\n",
      "Epoch 26/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2528 - accuracy: 0.6240\n",
      "Epoch 26: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_026-1.31.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2528 - accuracy: 0.6240 - val_loss: 1.3128 - val_accuracy: 0.6085 - lr: 4.0000e-04\n",
      "Epoch 27/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2370 - accuracy: 0.6318\n",
      "Epoch 27: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_027-1.30.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2370 - accuracy: 0.6318 - val_loss: 1.2996 - val_accuracy: 0.6158 - lr: 4.0000e-04\n",
      "Epoch 28/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2325 - accuracy: 0.6310\n",
      "Epoch 28: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_028-1.39.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2325 - accuracy: 0.6310 - val_loss: 1.3908 - val_accuracy: 0.5667 - lr: 4.0000e-04\n",
      "Epoch 29/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2239 - accuracy: 0.6371\n",
      "Epoch 29: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_029-1.35.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2239 - accuracy: 0.6371 - val_loss: 1.3486 - val_accuracy: 0.5915 - lr: 4.0000e-04\n",
      "Epoch 30/30\n",
      "505/505 [==============================] - ETA: 0s - loss: 1.2120 - accuracy: 0.6378\n",
      "Epoch 30: saving model to /content/gdrive/My Drive/Colab Notebooks/Checkpoints/FER_ResNet56_RoI_030-1.27.hdf5\n",
      "505/505 [==============================] - 79s 157ms/step - loss: 1.2120 - accuracy: 0.6378 - val_loss: 1.2685 - val_accuracy: 0.6180 - lr: 4.0000e-04\n"
     ]
    }
   ],
   "source": [
    "steps_per_epoch = math.ceil(train_data_count / BATCH_SIZE)\n",
    "validation_steps = math.ceil(test_data_count / BATCH_SIZE)\n",
    "\n",
    "history = model.fit(\n",
    "  x=train_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=EPOCHS,\n",
    "  initial_epoch=LAST_EPOCH,\n",
    "  callbacks=callbacks,\n",
    "  steps_per_epoch=steps_per_epoch,\n",
    "  validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5VVbTaJYUcc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_loss, train_acc = model.evaluate(\n",
    "  train_set,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  steps=steps_per_epoch\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(\n",
    "  test_set,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  steps=validation_steps\n",
    ")\n",
    "print(\"final train accuracy = {:.2f} , validation accuracy = {:.2f}\".format(train_acc*100, test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yXESD-aZrgl",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}